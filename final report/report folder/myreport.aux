\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{Glossary of Abbreviations}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Preface}{5}{section*.3}\protected@file@percent }
\citation{rajabov2025}
\citation{bach2018}
\citation{evolutionverlan}
\citation{evolutionverlan}
\citation{rajabov2025}
\citation{rua2005}
\citation{hajiyeva2025}
\citation{deepl2020}
\citation{wu2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{8}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Context and Motivation}{8}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Google Translate cannot translate the verlan \textit  {tebie} correctly.}}{9}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:google_verlan}{{1}{9}{Google Translate cannot translate the verlan \textit {tebie} correctly}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces DeepL cannot translate the verlan \textit  {tebie} correctly.}}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:deepl_verlan}{{2}{9}{DeepL cannot translate the verlan \textit {tebie} correctly}{figure.caption.5}{}}
\citation{pei2019slang}
\citation{michel2018mtnt}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces No desired translation for verlan \textit  {tebie} in DeepL's alternative word list.}}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:deepl_alt_text}{{3}{10}{No desired translation for verlan \textit {tebie} in DeepL's alternative word list}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objective}{10}{subsection.1.2}\protected@file@percent }
\citation{mela1991verlan}
\citation{kaye1984syllabicite}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{13}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}A Living Verlan}{13}{subsection.2.1}\protected@file@percent }
\newlabel{eq:verlan-perm}{{1}{13}{A Living Verlan}{equation.1}{}}
\citation{mela1991verlan}
\citation{mela1991verlan}
\citation{mela1991verlan}
\citation{zurbuchen2024}
\citation{podhorna2020rapcor}
\citation{mekki2021tremolo}
\citation{panckhurst202088milsms}
\citation{pei2019slang}
\citation{sun2024informal}
\citation{slangornot2024}
\citation{wu2018slangsd}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Detecting Slang}{14}{subsection.2.2}\protected@file@percent }
\citation{russell1918soundex}
\citation{levenshtein1966}
\citation{wagner1974string}
\citation{wagner1974string}
\citation{damerau1964}
\citation{navarro2001approximate}
\citation{zobel1996phonetic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}1910s-2010s: A Super-Condensed History of Slang Detection}{15}{subsubsection.2.2.1}\protected@file@percent }
\citation{philips1990metaphone}
\citation{philips2000doublemetaphone}
\citation{kukich1992techniques}
\citation{sproat2001normalization}
\citation{aw2006phrase}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classical fuzzy-match methods: strengths and limitations for slang/verlan.}}{16}{table.caption.9}\protected@file@percent }
\newlabel{tab:fuzzy_perf}{{1}{16}{Classical fuzzy-match methods: strengths and limitations for slang/verlan}{table.caption.9}{}}
\citation{dhuliawala2016slangnet}
\citation{wu2018slangsd}
\citation{gupta2019slangzy}
\citation{dictionnaire2024chilleur}
\citation{beaufort2010hybrid}
\citation{han2011lexical}
\citation{baldwin2015shared}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}2016-2019: Dictionary Search}{17}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Meanwhile, for Fuzzy Search}{17}{subsubsection.2.2.3}\protected@file@percent }
\citation{urban2020embeddings}
\citation{urban2020embeddings}
\citation{slangornot2024}
\citation{slangornot2024}
\citation{slangornot2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}2020-2025: Fuzzy Search + Slang Corpus = BOOM}{18}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Urban Dictionary embeddings (Wilson, 2020).}{18}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Slang or Not? (2024).}{18}{section*.11}\protected@file@percent }
\citation{sun2024informal}
\citation{sun2024informal}
\citation{slangornot2024}
\citation{urban2020embeddings}
\@writefile{toc}{\contentsline {paragraph}{Toward Informal Language Processing (NAACL 2024 Findings).}{19}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Detecting Verlan?}{19}{subsubsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Dataset}{20}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Separated Structures}{20}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Visualising the Dataset}{20}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Dataset at a glance (snapshot as of September 2025).}}{20}{table.caption.13}\protected@file@percent }
\newlabel{tab:dataset-glance}{{2}{20}{Dataset at a glance (snapshot as of September 2025)}{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Data Collection and Curation}{21}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Sampling}{21}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Balancing the Training Dataset}{22}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Evidence Levels (Source)}{24}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Evidence levels applied across the verlan dataset.}}{24}{table.caption.14}\protected@file@percent }
\newlabel{tab:verlan_tiers}{{3}{24}{Evidence levels applied across the verlan dataset}{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Dataset used in this report}{24}{subsection.3.4}\protected@file@percent }
\citation{jiang2023mistral7b}
\citation{jiang2023mistral7b}
\citation{touvron2023llama}
\citation{touvron2023llama2}
\citation{martin2019camembert}
\@writefile{toc}{\contentsline {section}{\numberline {4}Building the Pipelines --- Model Architectures and Specifications}{25}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Mistral 7B\tmspace  +\thickmuskip {.2777em}---\tmspace  +\thickmuskip {.2777em}Why?}{25}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Zero-Shot Models}{26}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Mistral 7B Prompt Engineering with Vibe}{26}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Zero-shot pipeline for Mistral}}{26}{figure.caption.16}\protected@file@percent }
\newlabel{fig:mistral-zeroshot-pipeline}{{4}{26}{Zero-shot pipeline for Mistral}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Zero-shot reference model}{27}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Artificial Analysis Intelligence Index (retrieved 14 Oct 2025). Our zero-shot reference, \textit  {GPT-5 Codex (High)}, is the model we evaluate.}}{28}{figure.caption.17}\protected@file@percent }
\newlabel{fig:AI_Index}{{5}{28}{Artificial Analysis Intelligence Index (retrieved 14 Oct 2025). Our zero-shot reference, \textit {GPT-5 Codex (High)}, is the model we evaluate}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Models}{29}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}The Pipelines}{29}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A compact view of the four verlan identification pipelines.\footnotesize   Exp~A: Frozen Encoder + Logistic Regression classifier Exp~B: End-to-End Encoder + Linear classifier Exp~C: Frozen Encoder + BERT-inspired classifier Exp~D: End-to-End Encoder + BERT-inspired classifier}}{30}{figure.caption.18}\protected@file@percent }
\newlabel{fig:pipeline-overview}{{6}{30}{A compact view of the four verlan identification pipelines.\footnotesize \\Exp~A: Frozen Encoder + Logistic Regression classifier\\Exp~B: End-to-End Encoder + Linear classifier\\Exp~C: Frozen Encoder + BERT-inspired classifier\\Exp~D: End-to-End Encoder + BERT-inspired classifier}{figure.caption.18}{}}
\citation{alsharou2021noise}
\@writefile{toc}{\contentsline {paragraph}{Input}{31}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sanitise Text}{31}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Why Not Preserve Upper Cases and Annotation Marks}{31}{section*.21}\protected@file@percent }
\citation{lodha2023surgical}
\@writefile{toc}{\contentsline {paragraph}{Tokenisation}{32}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Encoder}{32}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Post-encoder processing}{32}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Masking}{32}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Mean Pooling}{33}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{L2 Normalisation}{33}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The Classifiers\tmspace  +\thickmuskip {.2777em}---\tmspace  +\thickmuskip {.2777em}Logistic Regression and BERT-inspired MLPs}{33}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Logistic Regression}{34}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{BERT-Inspired Classifier}{34}{section*.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Classic BERT classifier module.}}{35}{figure.caption.31}\protected@file@percent }
\newlabel{fig:bert-classifier-module}{{7}{35}{Classic BERT classifier module}{figure.caption.31}{}}
\citation{paszke2019pytorch}
\citation{loshchilov2019adamw}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces BERT-style detection classifier (two-layer MLP on pooled Mistral embeddings).}}{36}{figure.caption.32}\protected@file@percent }
\newlabel{fig:bert-detect-classifier}{{8}{36}{BERT-style detection classifier (two-layer MLP on pooled Mistral embeddings)}{figure.caption.32}{}}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subparagraph}{Loss and optimisation}{37}{section*.33}\protected@file@percent }
\citation{loshchilov2019adamw}
\@writefile{toc}{\contentsline {paragraph}{The Sigmoid Threshold}{38}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}The Usage of the Dataset}{38}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Environment and Hyperparameters}{39}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Environment}{39}{figure.caption.36}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hyperparameters}{39}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Seeds}{39}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Batch Size}{39}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Maximum Length}{39}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Quantisation}{40}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Epochs}{40}{section*.42}\protected@file@percent }
\citation{pearson1901pca}
\citation{maaten2008tsne}
\citation{mcinnes2018umap}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluations, Results, and Analyses}{41}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Evaluation Methodology}{41}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Embedding Space}{41}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces UMAP visualisations of the embedding space showing verlan tokens (orange) and standard French tokens (blue).}}{42}{figure.caption.43}\protected@file@percent }
\newlabel{fig:umap_comparison}{{9}{42}{UMAP visualisations of the embedding space showing verlan tokens (orange) and standard French tokens (blue)}{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Testing Datasets}{42}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Testing Schema}{43}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Zero-shot Models}{43}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Number of Trials}{43}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Metrics}{44}{section*.46}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Binary confusion matrix (positive = verlan sentence, negative = standard sentence).}}{44}{figure.caption.47}\protected@file@percent }
\newlabel{fig:confusion-matrix-legend}{{10}{44}{Binary confusion matrix (positive = verlan sentence, negative = standard sentence)}{figure.caption.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results and Analyses}{44}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}General F1-Score and Accuracy}{44}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A general comparison of the F1 score and accuracy across models.}}{45}{figure.caption.48}\protected@file@percent }
\newlabel{fig:total-comparison}{{11}{45}{A general comparison of the F1 score and accuracy across models}{figure.caption.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Common Verlan Performance by Model}{45}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Models' performance in common verlan identification.}}{46}{figure.caption.49}\protected@file@percent }
\newlabel{fig:historical-verlan-comparison}{{12}{46}{Models' performance in common verlan identification}{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Invented Verlan Performance by Model}{47}{subsubsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Invented verlan performance by model.}}{47}{figure.caption.50}\protected@file@percent }
\newlabel{fig:invented-verlan-comparison}{{13}{47}{Invented verlan performance by model}{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Slang Controls Performance by Model}{48}{subsubsection.5.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Slang control accuracy.}}{48}{figure.caption.51}\protected@file@percent }
\newlabel{fig:slang-comparison}{{14}{48}{Slang control accuracy}{figure.caption.51}{}}
\@writefile{toc}{\contentsline {paragraph}{A Discussion on the Hook}{48}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}And Yet Something Advanced}{49}{subsubsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Is E2E+BERT the Real King?}{49}{section*.53}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Recall--specificity trade-off across models.}}{49}{figure.caption.54}\protected@file@percent }
\newlabel{fig:tradeoff-scatter}{{15}{49}{Recall--specificity trade-off across models}{figure.caption.54}{}}
\@writefile{toc}{\contentsline {paragraph}{Small Dataset Caused More Instability?}{50}{section*.55}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Invented verlan recall stability.}}{50}{figure.caption.56}\protected@file@percent }
\newlabel{fig:invented-variance}{{16}{50}{Invented verlan recall stability}{figure.caption.56}{}}
\@writefile{toc}{\contentsline {paragraph}{Again: Is E2E+BERT the Real King?}{50}{section*.57}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Link between slang false alarms and overall false positives.}}{51}{figure.caption.58}\protected@file@percent }
\newlabel{fig:slang-fp-correlation}{{17}{51}{Link between slang false alarms and overall false positives}{figure.caption.58}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion and Limitation}{52}{section.6}\protected@file@percent }
\bibcite{rajabov2025}{1}
\bibcite{bach2018}{2}
\bibcite{evolutionverlan}{3}
\bibcite{rua2005}{4}
\bibcite{hajiyeva2025}{5}
\bibcite{deepl2020}{6}
\bibcite{wu2016}{7}
\bibcite{michel2018mtnt}{8}
\bibcite{zurbuchen2024}{9}
\bibcite{podhorna2020rapcor}{10}
\bibcite{mekki2021tremolo}{11}
\bibcite{panckhurst202088milsms}{12}
\bibcite{pei2019slang}{13}
\bibcite{sun2024informal}{14}
\bibcite{slangornot2024}{15}
\bibcite{dhuliawala2016slangnet}{16}
\bibcite{wu2018slangsd}{17}
\bibcite{gupta2019slangzy}{18}
\bibcite{dictionnaire2024chilleur}{19}
\bibcite{mela1991verlan}{20}
\bibcite{kaye1984syllabicite}{21}
\bibcite{russell1918soundex}{22}
\bibcite{levenshtein1966}{23}
\bibcite{philips1990metaphone}{24}
\bibcite{philips2000doublemetaphone}{25}
\bibcite{kukich1992techniques}{26}
\bibcite{sproat2001normalization}{27}
\bibcite{aw2006phrase}{28}
\bibcite{beaufort2010hybrid}{29}
\bibcite{han2011lexical}{30}
\bibcite{baldwin2015shared}{31}
\bibcite{urban2020embeddings}{32}
\bibcite{sun2024knowledge}{33}
\bibcite{jiang2023mistral7b}{34}
\bibcite{touvron2023llama}{35}
\bibcite{touvron2023llama2}{36}
\bibcite{martin2019camembert}{37}
\bibcite{du2025deepresearch}{38}
\bibcite{dong2024imbalance}{39}
\bibcite{alsharou2021noise}{40}
\bibcite{lodha2023surgical}{41}
\bibcite{paszke2019pytorch}{42}
\bibcite{loshchilov2019adamw}{43}
\bibcite{kingma2014adam}{44}
\bibcite{pearson1901pca}{45}
\bibcite{maaten2008tsne}{46}
\bibcite{mcinnes2018umap}{47}
\bibcite{wagner1974string}{48}
\bibcite{navarro2001approximate}{49}
\bibcite{damerau1964}{50}
\bibcite{zobel1996phonetic}{51}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix A: Expanded Evaluation Artefacts}{60}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Hold-out test aggregates (20 seeds) for trained detectors. Percentages report mean $\pm $ standard deviation across seeds; counts are means.}}{60}{table.caption.60}\protected@file@percent }
\newlabel{tab:appendix-holdout-aggregates}{{4}{60}{Hold-out test aggregates (20 seeds) for trained detectors. Percentages report mean $\pm $ standard deviation across seeds; counts are means}{table.caption.60}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Targeted-slice comparison across 20 seeds. Historical and invented columns are verlan recalls; slang column measures rejection accuracy on contemporary slang controls.}}{60}{table.caption.61}\protected@file@percent }
\newlabel{tab:appendix-targeted-metrics}{{5}{60}{Targeted-slice comparison across 20 seeds. Historical and invented columns are verlan recalls; slang column measures rejection accuracy on contemporary slang controls}{table.caption.61}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Zero-shot targeted breakdowns (single pass). Metrics computed on 29 historical verlan, 25 invented verlan, and 25 slang sentences respectively.}}{60}{table.caption.62}\protected@file@percent }
\newlabel{tab:appendix-zeroshot-targeted}{{6}{60}{Zero-shot targeted breakdowns (single pass). Metrics computed on 29 historical verlan, 25 invented verlan, and 25 slang sentences respectively}{table.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Zero-shot recall lift on invented verlan relative to the best trained detector (Frozen+BERT).}}{61}{figure.caption.63}\protected@file@percent }
\newlabel{fig:invented-lift}{{18}{61}{Zero-shot recall lift on invented verlan relative to the best trained detector (Frozen+BERT)}{figure.caption.63}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Appendix B: Dataset schema (detailed)}{63}{appendix.B}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Detailed field-level schema for the dataset (columns, types, and relations between the lexicon and the sentence corpus).}}{63}{figure.caption.64}\protected@file@percent }
\newlabel{fig:dataset-schema-detailed}{{19}{63}{Detailed field-level schema for the dataset (columns, types, and relations between the lexicon and the sentence corpus)}{figure.caption.64}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Source buckets referenced in \texttt  {Sentences\_balanced.xlsx}. Counts come from the current spreadsheet (URLs and textual citations combined).}}{65}{table.caption.66}\protected@file@percent }
\newlabel{tab:source-inventory}{{7}{65}{Source buckets referenced in \texttt {Sentences\_balanced.xlsx}. Counts come from the current spreadsheet (URLs and textual citations combined)}{table.caption.66}{}}
\gdef \@abspage@last{67}
