\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{Glossary of Abbreviations}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Preface}{5}{section*.3}\protected@file@percent }
\citation{rajabov2025}
\citation{bach2018}
\citation{evolutionverlan}
\citation{evolutionverlan}
\citation{rajabov2025}
\citation{rua2005}
\citation{hajiyeva2025}
\citation{deepl2020}
\citation{wu2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{8}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Context and Motivation}{8}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Google Translate cannot translate the verlan \textit  {tebie} correctly.}}{9}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:google_verlan}{{1}{9}{Google Translate cannot translate the verlan \textit {tebie} correctly}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces DeepL cannot translate the verlan \textit  {tebie} correctly.}}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:deepl_verlan}{{2}{9}{DeepL cannot translate the verlan \textit {tebie} correctly}{figure.caption.5}{}}
\citation{pei2019slang}
\citation{michel2018mtnt}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces No desired translation for verlan \textit  {tebie} in DeepL's alternative word list.}}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:deepl_alt_text}{{3}{10}{No desired translation for verlan \textit {tebie} in DeepL's alternative word list}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objective}{10}{subsection.1.2}\protected@file@percent }
\citation{mela1991verlan}
\citation{kaye1984syllabicite}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{12}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}A Living Verlan}{12}{subsection.2.1}\protected@file@percent }
\newlabel{eq:verlan-perm}{{1}{12}{A Living Verlan}{equation.1}{}}
\citation{mela1991verlan}
\citation{mela1991verlan}
\citation{mela1991verlan}
\citation{zurbuchen2024}
\citation{podhorna2020rapcor}
\citation{mekki2021tremolo}
\citation{panckhurst202088milsms}
\citation{pei2019slang}
\citation{sun2024informal}
\citation{slangornot2024}
\citation{wu2018slangsd}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Detecting Slang}{13}{subsection.2.2}\protected@file@percent }
\citation{russell1918soundex}
\citation{levenshtein1966}
\citation{wagner1974string}
\citation{wagner1974string}
\citation{damerau1964}
\citation{navarro2001approximate}
\citation{zobel1996phonetic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}1910s-2010s: A Super-Condensed History of Slang Detection}{14}{subsubsection.2.2.1}\protected@file@percent }
\citation{philips1990metaphone}
\citation{philips2000doublemetaphone}
\citation{kukich1992techniques}
\citation{sproat2001normalization}
\citation{aw2006phrase}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classical fuzzy-match methods: strengths and limitations for slang/verlan.}}{15}{table.caption.9}\protected@file@percent }
\newlabel{tab:fuzzy_perf}{{1}{15}{Classical fuzzy-match methods: strengths and limitations for slang/verlan}{table.caption.9}{}}
\citation{dhuliawala2016slangnet}
\citation{wu2018slangsd}
\citation{gupta2019slangzy}
\citation{dictionnaire2024chilleur}
\citation{beaufort2010hybrid}
\citation{han2011lexical}
\citation{baldwin2015shared}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}2016-2019: Dictionary Search}{16}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Meanwhile, for Fuzzy Search}{16}{subsubsection.2.2.3}\protected@file@percent }
\citation{urban2020embeddings}
\citation{urban2020embeddings}
\citation{slangornot2024}
\citation{slangornot2024}
\citation{slangornot2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}2020-2025: Fuzzy Search + Slang Corpus = BOOM}{17}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Urban Dictionary embeddings (Wilson, 2020).}{17}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Slang or Not? (2024).}{17}{section*.11}\protected@file@percent }
\citation{sun2024informal}
\citation{sun2024informal}
\citation{slangornot2024}
\citation{urban2020embeddings}
\@writefile{toc}{\contentsline {paragraph}{Toward Informal Language Processing (NAACL 2024 Findings).}{18}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Detecting Verlan?}{18}{subsubsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Datasets}{18}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Separated Structures}{18}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Visualisation of the Datasets}{19}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The Creations}{19}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Overview of the GazetteerEntries lookup table and the Sentences corpus, including their key attributes.}}{20}{figure.caption.13}\protected@file@percent }
\newlabel{fig:dataset-structure}{{4}{20}{Overview of the GazetteerEntries lookup table and the Sentences corpus, including their key attributes}{figure.caption.13}{}}
\citation{du2025deepresearch}
\citation{dong2024imbalance}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Sampling}{21}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Balancing the Training Dataset}{21}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Quality Tiers}{22}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Quality tiers of the verlan datasets.}}{22}{table.caption.14}\protected@file@percent }
\newlabel{tab:verlan_tiers}{{2}{22}{Quality tiers of the verlan datasets}{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Final Dataset}{22}{subsection.3.4}\protected@file@percent }
\citation{jiang2023mistral7b}
\citation{martin2019camembert}
\citation{touvron2023llama}
\citation{touvron2023llama2}
\@writefile{toc}{\contentsline {section}{\numberline {4}Building the Pipelines --- Model Architectures and Specifications}{23}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Mistral 7B\tmspace  +\thickmuskip {.2777em}---\tmspace  +\thickmuskip {.2777em}Why?}{23}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Zero-Shot Models}{24}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Mistral 7B Prompt Engineering with Vibe}{24}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Zero-shot pipeline for Mistral}}{25}{figure.caption.16}\protected@file@percent }
\newlabel{fig:mistral-zeroshot-pipeline}{{5}{25}{Zero-shot pipeline for Mistral}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Zero-shot of the Most Powerful non deep reasoning LLM as reference}{26}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Leaderboard of the Artificial Analysis Intelligence Index (retrieved on 14 October 2025).}}{26}{figure.caption.17}\protected@file@percent }
\newlabel{fig:AI_Index}{{6}{26}{Leaderboard of the Artificial Analysis Intelligence Index (retrieved on 14 October 2025)}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Models}{27}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}The Pipelines}{28}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A compact view of the four verlan identification pipelines.\footnotesize   Exp~A: Frozen Encoder + LogisticRegression Head Exp~B: End-to-End Encoder + Linear Head Exp~C: Frozen Encoder + BERT-Style Head Exp~D: End-to-End Encoder + BERT-Style Head}}{29}{figure.caption.18}\protected@file@percent }
\newlabel{fig:pipeline-overview}{{7}{29}{A compact view of the four verlan identification pipelines.\footnotesize \\Exp~A: Frozen Encoder + LogisticRegression Head\\Exp~B: End-to-End Encoder + Linear Head\\Exp~C: Frozen Encoder + BERT-Style Head\\Exp~D: End-to-End Encoder + BERT-Style Head}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Input}{29}{section*.19}\protected@file@percent }
\citation{alsharou2021noise}
\@writefile{toc}{\contentsline {paragraph}{Normalise Text}{30}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Why Not Preserve Upper Cases and Annotation Marks}{30}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Tokenisation}{30}{section*.22}\protected@file@percent }
\citation{lodha2023surgical}
\@writefile{toc}{\contentsline {paragraph}{Encoder}{31}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Calibrations}{31}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Masking}{31}{section*.25}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Visulisation of masking.}}{32}{figure.caption.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Mean Pooling}{33}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{L2 Normalisation}{33}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The Classifiers\tmspace  +\thickmuskip {.2777em}---\tmspace  +\thickmuskip {.2777em}Logistic Regression or BERT}{34}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Logistic Regression with scikit-learn}{34}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{BERT-Style Head}{34}{section*.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Classic BERT classification head.}}{35}{figure.caption.32}\protected@file@percent }
\newlabel{fig:bert-classification-head}{{9}{35}{Classic BERT classification head}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces BERT-style detection head.}}{36}{figure.caption.33}\protected@file@percent }
\newlabel{fig:bert-detect-head}{{10}{36}{BERT-style detection head}{figure.caption.33}{}}
\citation{paszke2019pytorch}
\citation{loshchilov2019adamw}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subparagraph}{The Different Loss Function and Calibration}{37}{section*.34}\protected@file@percent }
\citation{loshchilov2019adamw}
\@writefile{toc}{\contentsline {paragraph}{The Sigmoid Threshold}{39}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}The Usage of the Dataset}{39}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Environment and Hyperparameters}{39}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Environment}{39}{figure.caption.37}\protected@file@percent }
\citation{pearson1901pca}
\citation{maaten2008tsne}
\citation{mcinnes2018umap}
\@writefile{toc}{\contentsline {paragraph}{Hyperparameters}{40}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Seeds}{40}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Batch Size}{40}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Maximum Length}{40}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Quantisation}{40}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Epochs}{40}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluations, Results, and Analyses}{40}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Evaluation Methodology}{40}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Embedding Space}{40}{subsubsection.5.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces UMAP visualisations of the embedding space showing the distribution of verlan and standard French tokens Class 1: verlan tokens Class 0: normal tokens}}{41}{figure.caption.44}\protected@file@percent }
\newlabel{fig:umap_comparison}{{11}{41}{UMAP visualisations of the embedding space showing the distribution of verlan and standard French tokens\\Class 1: verlan tokens\\Class 0: normal tokens}{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Testing Datasets}{42}{subsubsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3}Testing Schema}{42}{subsubsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Zero-shot Models}{42}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Number of Trials}{42}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Storing the Results}{43}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Analyse Methodology}{43}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Confusion Matrix}{43}{section*.49}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Binary confusion matrix.}}{43}{figure.caption.50}\protected@file@percent }
\newlabel{fig:confusion-matrix-legend}{{12}{43}{Binary confusion matrix}{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subparagraph}{Accuracy}{43}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{F1 Score}{43}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results and Analyses}{44}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}General F1-Score and Accuracy}{44}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A general comparison of the F1 score and accuracy across models.}}{44}{figure.caption.53}\protected@file@percent }
\newlabel{fig:total-comparison}{{13}{44}{A general comparison of the F1 score and accuracy across models}{figure.caption.53}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Common Verlan Performance by Model}{45}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Models' performance in common verlan identification.}}{46}{figure.caption.54}\protected@file@percent }
\newlabel{fig:historical-verlan-comparison}{{14}{46}{Models' performance in common verlan identification}{figure.caption.54}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Invented Verlan Performance by Model}{47}{subsubsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Invented verlan performance by model.}}{47}{figure.caption.55}\protected@file@percent }
\newlabel{fig:invented-verlan-comparison}{{15}{47}{Invented verlan performance by model}{figure.caption.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Slang Controls Performance by Model}{48}{subsubsection.5.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Slang control accuracy.}}{48}{figure.caption.56}\protected@file@percent }
\newlabel{fig:slang-comparison}{{16}{48}{Slang control accuracy}{figure.caption.56}{}}
\@writefile{toc}{\contentsline {paragraph}{A Discussion on the Hook}{48}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.5}And Yet Something Advanced}{49}{subsubsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Is E2E+BERT the Real King?}{49}{section*.58}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Recall--specificity trade-off across models.}}{49}{figure.caption.59}\protected@file@percent }
\newlabel{fig:tradeoff-scatter}{{17}{49}{Recall--specificity trade-off across models}{figure.caption.59}{}}
\@writefile{toc}{\contentsline {paragraph}{Small Dataset Caused More Instability?}{50}{section*.60}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Invented verlan recall stability.}}{50}{figure.caption.61}\protected@file@percent }
\newlabel{fig:invented-variance}{{18}{50}{Invented verlan recall stability}{figure.caption.61}{}}
\@writefile{toc}{\contentsline {paragraph}{Again: Is E2E+BERT the Real King?}{50}{section*.62}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Link between slang false alarms and overall false positives.}}{51}{figure.caption.63}\protected@file@percent }
\newlabel{fig:slang-fp-correlation}{{19}{51}{Link between slang false alarms and overall false positives}{figure.caption.63}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Conclusion and Limitation}{51}{subsection.5.3}\protected@file@percent }
\bibcite{rajabov2025}{1}
\bibcite{bach2018}{2}
\bibcite{evolutionverlan}{3}
\bibcite{rua2005}{4}
\bibcite{hajiyeva2025}{5}
\bibcite{deepl2020}{6}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion and Outlook}{52}{section.6}\protected@file@percent }
\bibcite{wu2016}{7}
\bibcite{michel2018mtnt}{8}
\bibcite{zurbuchen2024}{9}
\bibcite{podhorna2020rapcor}{10}
\bibcite{mekki2021tremolo}{11}
\bibcite{panckhurst202088milsms}{12}
\bibcite{pei2019slang}{13}
\bibcite{sun2024informal}{14}
\bibcite{slangornot2024}{15}
\bibcite{dhuliawala2016slangnet}{16}
\bibcite{wu2018slangsd}{17}
\bibcite{gupta2019slangzy}{18}
\bibcite{dictionnaire2024chilleur}{19}
\bibcite{mela1991verlan}{20}
\bibcite{kaye1984syllabicite}{21}
\bibcite{russell1918soundex}{22}
\bibcite{levenshtein1966}{23}
\bibcite{philips1990metaphone}{24}
\bibcite{philips2000doublemetaphone}{25}
\bibcite{kukich1992techniques}{26}
\bibcite{sproat2001normalization}{27}
\bibcite{aw2006phrase}{28}
\bibcite{beaufort2010hybrid}{29}
\bibcite{han2011lexical}{30}
\bibcite{baldwin2015shared}{31}
\bibcite{urban2020embeddings}{32}
\bibcite{sun2024knowledge}{33}
\bibcite{jiang2023mistral7b}{34}
\bibcite{touvron2023llama}{35}
\bibcite{touvron2023llama2}{36}
\bibcite{martin2019camembert}{37}
\bibcite{du2025deepresearch}{38}
\bibcite{dong2024imbalance}{39}
\bibcite{alsharou2021noise}{40}
\bibcite{lodha2023surgical}{41}
\bibcite{paszke2019pytorch}{42}
\bibcite{loshchilov2019adamw}{43}
\bibcite{kingma2014adam}{44}
\bibcite{pearson1901pca}{45}
\bibcite{maaten2008tsne}{46}
\bibcite{mcinnes2018umap}{47}
\bibcite{wagner1974string}{48}
\bibcite{navarro2001approximate}{49}
\bibcite{damerau1964}{50}
\bibcite{zobel1996phonetic}{51}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix A: Expanded Evaluation Artefacts}{59}{appendix.A}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Hold-out test aggregates (20 seeds) for trained detectors. Percentages report mean $\pm $ standard deviation across seeds; counts are means.}}{59}{table.caption.65}\protected@file@percent }
\newlabel{tab:appendix-holdout-aggregates}{{3}{59}{Hold-out test aggregates (20 seeds) for trained detectors. Percentages report mean $\pm $ standard deviation across seeds; counts are means}{table.caption.65}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Targeted-slice comparison across 20 seeds. Historical and invented columns are verlan recalls; slang column measures rejection accuracy on contemporary slang controls.}}{59}{table.caption.66}\protected@file@percent }
\newlabel{tab:appendix-targeted-metrics}{{4}{59}{Targeted-slice comparison across 20 seeds. Historical and invented columns are verlan recalls; slang column measures rejection accuracy on contemporary slang controls}{table.caption.66}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Zero-shot targeted breakdowns (single pass). Metrics computed on 29 historical verlan, 25 invented verlan, and 25 slang sentences respectively.}}{59}{table.caption.67}\protected@file@percent }
\newlabel{tab:appendix-zeroshot-targeted}{{5}{59}{Zero-shot targeted breakdowns (single pass). Metrics computed on 29 historical verlan, 25 invented verlan, and 25 slang sentences respectively}{table.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Zero-shot recall lift on invented verlan relative to the best trained detector (Frozen+BERT).}}{60}{figure.caption.68}\protected@file@percent }
\newlabel{fig:invented-lift}{{20}{60}{Zero-shot recall lift on invented verlan relative to the best trained detector (Frozen+BERT)}{figure.caption.68}{}}
\gdef \@abspage@last{61}
