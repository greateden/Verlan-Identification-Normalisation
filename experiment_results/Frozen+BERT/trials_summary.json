[
  {
    "seed": 1,
    "run_id": "seed-1",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-1",
    "val_best_f1@0.5": 0.7965517241379311,
    "test_f1@0.5": 0.7774566473988439,
    "test_acc@0.5": 0.8194607268464243,
    "test_fp@0.5": 103,
    "test_fn@0.5": 51,
    "slang_tn@0.5": 42,
    "slang_fp@0.5": 8,
    "slang_accuracy@0.5": 0.84,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8235294117647058,
    "verlan_test_set_invented_accuracy@0.5": 0.68,
    "verlan_test_set_invented_f1@0.5": 0.5294117647058824
  },
  {
    "seed": 2,
    "run_id": "seed-2",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-2",
    "val_best_f1@0.5": 0.8089500860585198,
    "test_f1@0.5": 0.8135095447870778,
    "test_acc@0.5": 0.8511137162954279,
    "test_fp@0.5": 84,
    "test_fn@0.5": 43,
    "slang_tn@0.5": 43,
    "slang_fp@0.5": 7,
    "slang_accuracy@0.5": 0.86,
    "verlan_test_set_accuracy@0.5": 0.896551724137931,
    "verlan_test_set_f1@0.5": 0.8888888888888888,
    "verlan_test_set_invented_accuracy@0.5": 0.68,
    "verlan_test_set_invented_f1@0.5": 0.6
  },
  {
    "seed": 3,
    "run_id": "seed-3",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-3",
    "val_best_f1@0.5": 0.7758346581875993,
    "test_f1@0.5": 0.7704485488126649,
    "test_acc@0.5": 0.7960140679953107,
    "test_fp@0.5": 146,
    "test_fn@0.5": 28,
    "slang_tn@0.5": 35,
    "slang_fp@0.5": 15,
    "slang_accuracy@0.5": 0.7,
    "verlan_test_set_accuracy@0.5": 0.896551724137931,
    "verlan_test_set_f1@0.5": 0.8928571428571429,
    "verlan_test_set_invented_accuracy@0.5": 0.8,
    "verlan_test_set_invented_f1@0.5": 0.7727272727272727
  },
  {
    "seed": 4,
    "run_id": "seed-4",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-4",
    "val_best_f1@0.5": 0.7811023622047244,
    "test_f1@0.5": 0.782051282051282,
    "test_acc@0.5": 0.8007033997655334,
    "test_fp@0.5": 155,
    "test_fn@0.5": 15,
    "slang_tn@0.5": 35,
    "slang_fp@0.5": 15,
    "slang_accuracy@0.5": 0.7,
    "verlan_test_set_accuracy@0.5": 0.8620689655172413,
    "verlan_test_set_f1@0.5": 0.8461538461538461,
    "verlan_test_set_invented_accuracy@0.5": 0.76,
    "verlan_test_set_invented_f1@0.5": 0.7142857142857143
  },
  {
    "seed": 5,
    "run_id": "seed-5",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-5",
    "val_best_f1@0.5": 0.7571644042232277,
    "test_f1@0.5": 0.7610389610389611,
    "test_acc@0.5": 0.7842907385697538,
    "test_fp@0.5": 157,
    "test_fn@0.5": 27,
    "slang_tn@0.5": 35,
    "slang_fp@0.5": 15,
    "slang_accuracy@0.5": 0.7,
    "verlan_test_set_accuracy@0.5": 0.8793103448275862,
    "verlan_test_set_f1@0.5": 0.8771929824561403,
    "verlan_test_set_invented_accuracy@0.5": 0.78,
    "verlan_test_set_invented_f1@0.5": 0.7659574468085106
  },
  {
    "seed": 6,
    "run_id": "seed-6",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-6",
    "val_best_f1@0.5": 0.7526501766784452,
    "test_f1@0.5": 0.7969465648854962,
    "test_acc@0.5": 0.8440797186400938,
    "test_fp@0.5": 74,
    "test_fn@0.5": 59,
    "slang_tn@0.5": 44,
    "slang_fp@0.5": 6,
    "slang_accuracy@0.5": 0.88,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8163265306122449,
    "verlan_test_set_invented_accuracy@0.5": 0.64,
    "verlan_test_set_invented_f1@0.5": 0.5263157894736842
  },
  {
    "seed": 7,
    "run_id": "seed-7",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-7",
    "val_best_f1@0.5": 0.7597955706984668,
    "test_f1@0.5": 0.7707736389684814,
    "test_acc@0.5": 0.8124267291910903,
    "test_fp@0.5": 109,
    "test_fn@0.5": 51,
    "slang_tn@0.5": 42,
    "slang_fp@0.5": 8,
    "slang_accuracy@0.5": 0.84,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8235294117647058,
    "verlan_test_set_invented_accuracy@0.5": 0.72,
    "verlan_test_set_invented_f1@0.5": 0.631578947368421
  },
  {
    "seed": 8,
    "run_id": "seed-8",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-8",
    "val_best_f1@0.5": 0.7801418439716312,
    "test_f1@0.5": 0.793002915451895,
    "test_acc@0.5": 0.8335287221570926,
    "test_fp@0.5": 94,
    "test_fn@0.5": 48,
    "slang_tn@0.5": 40,
    "slang_fp@0.5": 10,
    "slang_accuracy@0.5": 0.8,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8235294117647058,
    "verlan_test_set_invented_accuracy@0.5": 0.72,
    "verlan_test_set_invented_f1@0.5": 0.631578947368421
  },
  {
    "seed": 9,
    "run_id": "seed-9",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-9",
    "val_best_f1@0.5": 0.7967741935483871,
    "test_f1@0.5": 0.7722222222222223,
    "test_acc@0.5": 0.8077373974208675,
    "test_fp@0.5": 122,
    "test_fn@0.5": 42,
    "slang_tn@0.5": 41,
    "slang_fp@0.5": 9,
    "slang_accuracy@0.5": 0.82,
    "verlan_test_set_accuracy@0.5": 0.8620689655172413,
    "verlan_test_set_f1@0.5": 0.8518518518518519,
    "verlan_test_set_invented_accuracy@0.5": 0.7,
    "verlan_test_set_invented_f1@0.5": 0.6511627906976745
  },
  {
    "seed": 10,
    "run_id": "seed-10",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-10",
    "val_best_f1@0.5": 0.7937608318890814,
    "test_f1@0.5": 0.7987897125567323,
    "test_acc@0.5": 0.8440797186400938,
    "test_fp@0.5": 77,
    "test_fn@0.5": 56,
    "slang_tn@0.5": 43,
    "slang_fp@0.5": 7,
    "slang_accuracy@0.5": 0.86,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8235294117647058,
    "verlan_test_set_invented_accuracy@0.5": 0.68,
    "verlan_test_set_invented_f1@0.5": 0.5555555555555556
  },
  {
    "seed": 11,
    "run_id": "seed-11",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-11",
    "val_best_f1@0.5": 0.773851590106007,
    "test_f1@0.5": 0.7526555386949925,
    "test_acc@0.5": 0.8089097303634232,
    "test_fp@0.5": 91,
    "test_fn@0.5": 72,
    "slang_tn@0.5": 43,
    "slang_fp@0.5": 7,
    "slang_accuracy@0.5": 0.86,
    "verlan_test_set_accuracy@0.5": 0.8103448275862069,
    "verlan_test_set_f1@0.5": 0.7843137254901961,
    "verlan_test_set_invented_accuracy@0.5": 0.72,
    "verlan_test_set_invented_f1@0.5": 0.6111111111111112
  },
  {
    "seed": 12,
    "run_id": "seed-12",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-12",
    "val_best_f1@0.5": 0.7751371115173674,
    "test_f1@0.5": 0.7763975155279503,
    "test_acc@0.5": 0.8311840562719812,
    "test_fp@0.5": 74,
    "test_fn@0.5": 70,
    "slang_tn@0.5": 44,
    "slang_fp@0.5": 6,
    "slang_accuracy@0.5": 0.88,
    "verlan_test_set_accuracy@0.5": 0.8275862068965517,
    "verlan_test_set_f1@0.5": 0.7916666666666666,
    "verlan_test_set_invented_accuracy@0.5": 0.68,
    "verlan_test_set_invented_f1@0.5": 0.5294117647058824
  },
  {
    "seed": 13,
    "run_id": "seed-13",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-13",
    "val_best_f1@0.5": 0.7790893760539629,
    "test_f1@0.5": 0.7988505747126436,
    "test_acc@0.5": 0.835873388042204,
    "test_fp@0.5": 98,
    "test_fn@0.5": 42,
    "slang_tn@0.5": 42,
    "slang_fp@0.5": 8,
    "slang_accuracy@0.5": 0.84,
    "verlan_test_set_accuracy@0.5": 0.8620689655172413,
    "verlan_test_set_f1@0.5": 0.8518518518518519,
    "verlan_test_set_invented_accuracy@0.5": 0.74,
    "verlan_test_set_invented_f1@0.5": 0.6666666666666666
  },
  {
    "seed": 14,
    "run_id": "seed-14",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-14",
    "val_best_f1@0.5": 0.7849462365591398,
    "test_f1@0.5": 0.7737003058103975,
    "test_acc@0.5": 0.8264947245017585,
    "test_fp@0.5": 81,
    "test_fn@0.5": 67,
    "slang_tn@0.5": 42,
    "slang_fp@0.5": 8,
    "slang_accuracy@0.5": 0.84,
    "verlan_test_set_accuracy@0.5": 0.8103448275862069,
    "verlan_test_set_f1@0.5": 0.7659574468085106,
    "verlan_test_set_invented_accuracy@0.5": 0.68,
    "verlan_test_set_invented_f1@0.5": 0.5294117647058824
  },
  {
    "seed": 15,
    "run_id": "seed-15",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-15",
    "val_best_f1@0.5": 0.7793103448275862,
    "test_f1@0.5": 0.8092485549132948,
    "test_acc@0.5": 0.8452520515826495,
    "test_fp@0.5": 92,
    "test_fn@0.5": 40,
    "slang_tn@0.5": 43,
    "slang_fp@0.5": 7,
    "slang_accuracy@0.5": 0.86,
    "verlan_test_set_accuracy@0.5": 0.8793103448275862,
    "verlan_test_set_f1@0.5": 0.8679245283018868,
    "verlan_test_set_invented_accuracy@0.5": 0.7,
    "verlan_test_set_invented_f1@0.5": 0.5945945945945946
  },
  {
    "seed": 16,
    "run_id": "seed-16",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-16",
    "val_best_f1@0.5": 0.7884615384615384,
    "test_f1@0.5": 0.7472527472527473,
    "test_acc@0.5": 0.8112543962485346,
    "test_fp@0.5": 79,
    "test_fn@0.5": 82,
    "slang_tn@0.5": 45,
    "slang_fp@0.5": 5,
    "slang_accuracy@0.5": 0.9,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8163265306122449,
    "verlan_test_set_invented_accuracy@0.5": 0.62,
    "verlan_test_set_invented_f1@0.5": 0.3870967741935484
  },
  {
    "seed": 17,
    "run_id": "seed-17",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-17",
    "val_best_f1@0.5": 0.7944732297063903,
    "test_f1@0.5": 0.781010719754977,
    "test_acc@0.5": 0.8323563892145369,
    "test_fp@0.5": 78,
    "test_fn@0.5": 65,
    "slang_tn@0.5": 43,
    "slang_fp@0.5": 7,
    "slang_accuracy@0.5": 0.86,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8235294117647058,
    "verlan_test_set_invented_accuracy@0.5": 0.7,
    "verlan_test_set_invented_f1@0.5": 0.6153846153846154
  },
  {
    "seed": 18,
    "run_id": "seed-18",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-18",
    "val_best_f1@0.5": 0.8274706867671692,
    "test_f1@0.5": 0.784992784992785,
    "test_acc@0.5": 0.8253223915592028,
    "test_fp@0.5": 101,
    "test_fn@0.5": 48,
    "slang_tn@0.5": 40,
    "slang_fp@0.5": 10,
    "slang_accuracy@0.5": 0.8,
    "verlan_test_set_accuracy@0.5": 0.8448275862068966,
    "verlan_test_set_f1@0.5": 0.8235294117647058,
    "verlan_test_set_invented_accuracy@0.5": 0.72,
    "verlan_test_set_invented_f1@0.5": 0.65
  },
  {
    "seed": 19,
    "run_id": "seed-19",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-19",
    "val_best_f1@0.5": 0.7876823338735819,
    "test_f1@0.5": 0.7859078590785907,
    "test_acc@0.5": 0.8147713950762017,
    "test_fp@0.5": 128,
    "test_fn@0.5": 30,
    "slang_tn@0.5": 35,
    "slang_fp@0.5": 15,
    "slang_accuracy@0.5": 0.7,
    "verlan_test_set_accuracy@0.5": 0.8620689655172413,
    "verlan_test_set_f1@0.5": 0.8571428571428571,
    "verlan_test_set_invented_accuracy@0.5": 0.8,
    "verlan_test_set_invented_f1@0.5": 0.7619047619047619
  },
  {
    "seed": 20,
    "run_id": "seed-20",
    "run_dir": "/projects/sciences/computing/liyi5784/Verlan-Identification-Normalisation-main/experiment_results/Frozen+BERT/seed-20",
    "val_best_f1@0.5": 0.7936507936507936,
    "test_f1@0.5": 0.76,
    "test_acc@0.5": 0.8171160609613131,
    "test_fp@0.5": 83,
    "test_fn@0.5": 73,
    "slang_tn@0.5": 41,
    "slang_fp@0.5": 9,
    "slang_accuracy@0.5": 0.82,
    "verlan_test_set_accuracy@0.5": 0.8793103448275862,
    "verlan_test_set_f1@0.5": 0.8679245283018868,
    "verlan_test_set_invented_accuracy@0.5": 0.64,
    "verlan_test_set_invented_f1@0.5": 0.47058823529411764
  }
]